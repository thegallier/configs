MemGPT is a system that enables large language models (LLMs) to manage extended contexts by emulating operating system memory hierarchies. It divides memory into main context (active prompt tokens) and external context (persistent storage), allowing the LLM to dynamically read from and write to these storage tiers. This design facilitates the retrieval of pertinent historical data and the eviction of less relevant information, effectively providing the illusion of an infinite context window. By employing function calls to handle control flow and memory management, MemGPT allows LLMs to maintain continuity over long-term interactions and analyze documents that exceed their native context limitations. ￼

To generate user-specific responses, MemGPT can store personalized information in its external context. When a user engages with the system, the LLM can retrieve this stored data and incorporate it into the prompt, tailoring responses to the individual’s preferences and history. This approach ensures that interactions are contextually relevant and personalized, enhancing the user experience by leveraging the system’s managed memory to maintain and utilize user-specific information effectively.

For a comprehensive understanding of MemGPT’s architecture and capabilities, you can access the full paper here: ￼



direct Preference Optimization (DPO) is a technique for fine-tuning large language models (LLMs) to align with human preferences without the complexities of traditional reinforcement learning methods. Unlike Reinforcement Learning from Human Feedback (RLHF), which involves training a separate reward model and then optimizing the LLM to maximize this estimated reward, DPO directly adjusts the LLM using preference data. This approach simplifies the alignment process, enhancing stability and computational efficiency. Empirical studies have demonstrated that DPO can match or surpass the performance of RLHF in tasks such as sentiment control, summarization, and dialogue generation, while being more straightforward to implement and train. ￼


Literature List

	1.	UMAP: rporate user profiles to distinguish between different user needs (e.g., code vs. Excel users, rates vs. credit users).

Utilizing Agents for Iterative Improvement

	•	Goal: Test dp calls and refine answers for optimal solutions.
	•	Technology: Leverage asynchronous agent capabilities offered by platforms like Microsoft’s latest offerings.

Integration of User Feedback

	•	Strategy: Continuously incorporate insights from users to enhance system functionality.
	•	Benefit: Ensure the system evolves in alignment with user needs.

Exploiting Large Context Windows in Newer Models

	•	Advantage: Guide the LLM to produce more relevant results through multi-step reasoning.
	•	Outcome: Improve answer accuracy and expand the complexity of queries the system can handle.

Integration of Code and Data Augmentation

	•	Aim: Enrich the system’s knowledge base with practical code examples.
	•	Technique: Augment input data to cover a broader range of scenarios and use cases.

Model Merging and Optimization

	•	Objective: Combine the strengths of different models to enhance performance.
	•	Challenge: Ensure seamless integration without compromising individual model capabilities.

Expanding the Project Scope

	•	Vision: Utilize advancements in AI to broaden the functionalities and applications of the system.
	•	Expectation: Achieve more relevant answers and cater to a wider array of user needs.

Enhancing Retrieval Results

	•	Reordering RAG Results with User Usage Data: Prioritizes information based on actual user interactions with the dp library.
	•	Best-of-3 Approach with Fine-Tuned Models: Improves answer quality by selecting the best response from multiple models.
	•	Language Model Integration: Combines answers using LLMs for coherent and comprehensive responses.

User Feedback Collection

	•	Engagement with David’s Team: Gathered insights to refine the system based on real-world usage and requirements.
	•	Deployment in Arena: Provided a testing ground to evaluate system performance and gather additional feedback.

Challenges


The dp library’s significance lies in its adaptability:
	•	Sales and Trading Teams: Utilize the Excel interface for rapid calculations and decision-making.
	•	Development Teams: Integrate the library into larger systems for comprehensive risk assessment and regulatory compliance.
	•	Quantitative Developers: Leverage the Python interface to build advanced analytics and models.

Project Description: Enhancing the dp Library for Fixed Income Securities Pricing and Risk Management

Executive Summary

The dp library is a proprietary tool utilized by Citi for the pricing and risk management of fixed income securities. Accessible via Excel and Python, it serves thousands of users across markets. These users span a wide range—from sales and trading professionals using Excel, development teams integrating the library into risk and regulatory systems, to quantitative developers crafting sophisticated analytics.

Despite its widespread use, the dp library faces several challenges, including inconsistent naming conventions, legacy code complexities, and discrepancies between its Excel and Python versions. To address these issues, we have developed a retrieval-augmented question-answering system combined with a fine-tuned large language model (LLM). This system leverages advanced clustering techniques, specifically a method called Raptor, to enhance information retrieval and user experience. Our future plans involve refining this system further by integrating user feedback, enhancing model capabilities, and expanding the project’s scope to harness advancements in AI.
Current Achievements

To address these challenges, significant progress has been made:

Development of a Retrieval-Augmented Question Answering System

	•	Integration with Fine-Tuned LLM: Combines the strengths of LLMs with retrieval mechanisms to provide accurate, context-aware responses.
	•	Generated a Dataset of 20,000 Q&A Pairs: Standardizes language and improves model training by summarizing wiki packages and test case code.

Implementation of Raptor for Hierarchical Clustering

	•	Based on UMAP and Riemannian Manifolds: Captures the intrinsic geometry of data for better clustering.
	•	Gaussian Mixture Modeling: Allows information chunks to belong to multiple categories, enhancing retrieval relevance.
Diagram 1: Raptor Clustering Method

Conclusion

The dp library is integral to Citi’s operations in fixed income securities pricing and risk management. By addressing its current challenges through advanced AI techniques and user-centric enhancements, we can significantly improve its usability and efficiency. The strides made thus far lay a solid foundation, and the planned future developments promise to deliver a state-of-the-art system that meets and exceeds the diverse needs of its users.

